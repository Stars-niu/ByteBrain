---
license: other
license_name: license-yuan
license_link: https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/LICENSE-Yuan
---

<div align="center">
<h1>
  Yuan 2
</h1>
</div>

<div align="center">
<a href="https://github.com/IEIT-Yuan/Yuan-2.0" target="_blank"> ğŸ’»GitHub Repo</a> | <a href="http://arxiv.org/pdf/2311.15786.pdf" target="_blank">ğŸ“ƒYuan2.0-paper</a>
</div>

# ç›®å½•/Table of Contents

- [æ¨¡å‹ä»‹ç»/Introduction](#Introduction)
- [ä»£ç è°ƒç”¨/Code Usage](#Usage)
- [Benchmarkè¯„ä¼°/Benchmark Evaluation](#Benchmark)
- [å£°æ˜ä¸åè®®/Terms and Conditions](#Terms)
- [å¼•ç”¨/Cite](#Cite)


# <span id="Introduction">æ¨¡å‹ä»‹ç»/Introduction</span>
æº2.0 æ˜¯æµªæ½®ä¿¡æ¯å‘å¸ƒçš„æ–°ä¸€ä»£åŸºç¡€è¯­è¨€å¤§æ¨¡å‹ã€‚æˆ‘ä»¬å¼€æºäº†å…¨éƒ¨çš„3ä¸ªæ¨¡å‹æº2.0-102Bï¼Œæº2.0-51Bå’Œæº2.0-2Bã€‚å¹¶ä¸”æˆ‘ä»¬æä¾›äº†é¢„è®­ç»ƒï¼Œå¾®è°ƒï¼Œæ¨ç†æœåŠ¡çš„ç›¸å…³è„šæœ¬ï¼Œä»¥ä¾›ç ”å‘äººå‘˜åšè¿›ä¸€æ­¥çš„å¼€å‘ã€‚æº2.0æ˜¯åœ¨æº1.0çš„åŸºç¡€ä¸Šï¼Œåˆ©ç”¨æ›´å¤šæ ·çš„é«˜è´¨é‡é¢„è®­ç»ƒæ•°æ®å’ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œä»¤æ¨¡å‹åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç ã€çŸ¥è¯†ç­‰ä¸åŒæ–¹é¢å…·å¤‡æ›´å¼ºçš„ç†è§£èƒ½åŠ›ã€‚

Yuan2.0 is a new generation Fundamental Large Language Model developed by IEIT System. We have published all three models, Yuan 2.0-102B, Yuan 2.0-51B, and Yuan 2.0-2B. And we provide relevant scripts for pretraining, fine-tuning, and inference services for other developers. Yuan2.0 is based on Yuan1.0, utilizing a wider range of high-quality pre training data and instruction fine-tuning datasets to enhance the model's understanding of semantics, mathematics, reasoning, code, knowledge, and other aspects.


# <span id="Usage">ä»£ç è°ƒç”¨/Code Usage</span>
å¯ä»¥é€šè¿‡å¦‚ä¸‹ä»£ç è°ƒç”¨ Yuan2-2B æ¨¡å‹æ¥ç”Ÿæˆæ–‡æœ¬ï¼š

You can generate text by invoking the Yuan2-2B model with the following code:

```python
import torch, transformers
import sys, os
sys.path.append(
    os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir)))
from transformers import AutoModelForCausalLM,AutoTokenizer,LlamaTokenizer

print("Creat tokenizer...")
tokenizer = LlamaTokenizer.from_pretrained('IEITYuan/Yuan2-2B-Februa-hf', add_eos_token=False, add_bos_token=False, eos_token='<eod>')
tokenizer.add_tokens(['<sep>', '<pad>', '<mask>', '<predict>', '<FIM_SUFFIX>', '<FIM_PREFIX>', '<FIM_MIDDLE>','<commit_before>','<commit_msg>','<commit_after>','<jupyter_start>','<jupyter_text>','<jupyter_code>','<jupyter_output>','<empty_output>'], special_tokens=True)

print("Creat model...")
model = AutoModelForCausalLM.from_pretrained('IEITYuan/Yuan2-2B-Februa-hf', device_map='auto', torch_dtype=torch.bfloat16, trust_remote_code=True)

inputs = tokenizer("è¯·é—®ç›®å‰æœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ ç®—æ³•æœ‰å“ªäº›ï¼Ÿ", return_tensors="pt")["input_ids"].to("cuda:0")
outputs = model.generate(inputs,do_sample=False,max_length=100)
print(tokenizer.decode(outputs[0]))

```

# <span id="Benchmark">Benchmarkè¯„ä¼°/Benchmark Evaluation</span>
æˆ‘ä»¬æä¾›äº†[HumanEval](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/eval_humaneval.md)ï¼Œ[AGIEval-GK-Math](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/eval_agieval_math.md)ï¼Œ[GSM8K](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/eval_gsm8k.md)å’Œ[TruthfulQA](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/eval_TruthfulQA.md)çš„è¯„ä¼°è„šæœ¬ã€‚åœ¨4ä¸ªå…¸å‹ä»»åŠ¡ä¸Šï¼Œæˆ‘ä»¬ç”¨æº2.0ä¸åŒç‰ˆæœ¬æ¨¡å‹ä¸Šè¿›è¡Œäº†æ€§èƒ½æµ‹è¯•ã€‚

We have provided evaluation scripts for [HumanEval](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/eval_humaneval.md),[AGIEval-GK-Math](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/eval_agieval_math.md),[GSM8K](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/eval_gsm8k.md) and [TruthfulQA](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/eval_TruthfulQA.md). Performance tests were conducted on different versions of the Yuan2.0 model for four typical tasks.


| Model             | GSM8K   | AGIEval-GK-Math-QA     | AGIEval-GK-Math-Cloze     | HumanEval | TurthfulQA |
| ----------------- | :----:  | :------------: | :---------------: | :-------: | ---------- |
|  GPT-4            |  92%    |     47.0%      |       16.1%       |   86.6%   |     59%    |
|  ChatGPT         | 68.6%\* |     36.5%      |        7.3%       |  66.5%\*  |     34%\*  |
|  Llama2           | 56.8%   |       -        |         -         |   29.9%   |       -    |
| æº2.0-102B      | 76.6%   |     38.7%      |       13.5%       |   67.1%   |     58%    |
| æº2.0-102B-SC   | 86.2%   |     45.5%      |       15.2%       |   77.4%   |       -    |

\* ä½¿ç”¨ä¸æº2.0å®Œå…¨ç›¸åŒçš„è¾“å…¥æ•°æ®å¯¹ChatGPTè¿›è¡Œæµ‹è¯•ï¼Œæ—¶é—´2023å¹´11æœˆ

\* Testing ChatGPT using the same input data as Yuan2.0, as of November 2023.

# <span id="Terms">å£°æ˜ä¸åè®®/Terms and Conditions</span>
å¯¹è¯¥æ¨¡å‹çš„åŸä»£ç ä»“åº“ä½¿ç”¨éµå¾ªå¼€æºè®¸å¯åè®® Apache 2.0ã€‚

æº2.0æ¨¡å‹æ”¯æŒå•†ç”¨ï¼Œä¸éœ€è¦ç”³è¯·æˆæƒï¼Œè¯·æ‚¨äº†è§£å¹¶éµå¾ª[ã€Šæº2.0æ¨¡å‹è®¸å¯åè®®ã€‹](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/LICENSE-Yuan)ï¼Œå‹¿å°†å¼€æºæ¨¡å‹å’Œä»£ç åŠåŸºäºå¼€æºé¡¹ç›®äº§ç”Ÿçš„è¡ç”Ÿç‰©ç”¨äºä»»ä½•å¯èƒ½ç»™å›½å®¶å’Œç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ä»¥åŠç”¨äºä»»ä½•æœªç»è¿‡å®‰å…¨è¯„ä¼°å’Œå¤‡æ¡ˆçš„æœåŠ¡ã€‚

å°½ç®¡æ¨¡å‹åœ¨è®­ç»ƒæ—¶æˆ‘ä»¬å·²é‡‡å–æªæ–½å°½åŠ›ç¡®ä¿æ•°æ®çš„åˆè§„æ€§å’Œå‡†ç¡®æ€§ï¼Œä½†æ¨¡å‹å‚æ•°é‡å·¨å¤§ä¸”å—æ¦‚ç‡éšæœºæ€§å› ç´ å½±å“ï¼Œæˆ‘ä»¬æ— æ³•ä¿è¯è¾“å‡ºå†…å®¹çš„å‡†ç¡®æ€§ï¼Œä¸”æ¨¡å‹æ˜“è¢«è¾“å…¥æŒ‡ä»¤æ‰€è¯¯å¯¼ï¼Œæœ¬é¡¹ç›®ä¸æ‰¿æ‹…å¼€æºæ¨¡å‹å’Œä»£ç å¯¼è‡´çš„æ•°æ®å®‰å…¨ã€èˆ†æƒ…é£é™©æˆ–å‘ç”Ÿä»»ä½•æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­ã€ä¸å½“åˆ©ç”¨è€Œäº§ç”Ÿçš„é£é™©å’Œè´£ä»»ã€‚**æ‚¨å°†å¯¹é€šè¿‡ä½¿ç”¨ã€å¤åˆ¶ã€åˆ†å‘å’Œä¿®æ”¹æ¨¡å‹ç­‰æ–¹å¼åˆ©ç”¨è¯¥å¼€æºé¡¹ç›®æ‰€äº§ç”Ÿçš„é£é™©ä¸åæœï¼Œç‹¬è‡ªæ‰¿æ‹…å…¨éƒ¨è´£ä»»ã€‚**

The use of the original code repository for this model requires compliance with the open source license agreement Apache 2.0. The Yuan2.0 model supports commercial use and does not require authorization. Please understand and comply with the [ã€ŠYuan 2.0 Model License Agreementã€‹](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/LICENSE-Yuan). Do not use the open source model and code, as well as derivatives generated from open source projects, for any purposes that may cause harm to the country and society, or for any services that have not undergone security assessment and filing. Although we have taken measures to ensure the compliance and accuracy of the data during training, the model has a huge number of parameters and is affected by probability and randomness factors. We cannot guarantee the accuracy of the output content, and the model is easily misled by input instructions. This project does not assume any data security, public opinion risks, or any model misleading, abusing, spreading caused by open-source models and code Risks and responsibilities arising from improper utilization **You will be solely responsible for the risks and consequences arising from the use, copying, distribution, and modification of the model in this open source project.**

# <span id="Cite">å¼•ç”¨/Cite</span>
æ¬¢è¿é˜…è¯»æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Š [YUAN 2.0: A Large Language Model with Localized Filtering-based Attention](http://arxiv.org/pdf/2311.15786.pdf)ï¼

Welcome to read our technical report [YUAN 2.0: A Large Language Model with Localized Filtering-based Attention](http://arxiv.org/pdf/2311.15786.pdf)ï¼

```latex
@article{Wu2023,
title = {{YUAN 2.0: A Large Language Model with Localized Filtering-based Attention}},
author = {Wu, Shaohua and Zhao, Xudong and Wang, Shenling and Luo, Jiangang and Li, Lingjun and Chen, Xi and Zhao, Bing and Wang, Wei and Yu, Tong and Zhang, Rongguo and Zhang, Jiahua and Wang, Chao},
url = {http://arxiv.org/abs/2311.15786},
year = {2023}
}

```
